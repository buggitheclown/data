---
title: "Group 1 Report"
author: "Julian Cornea, Kim Ferres, Jan LÃ¶ffelmann"
date: "23-05-2019"
output:
  bookdown::html_document2:
    toc: yes
    toc_float: true
    theme: flatly
---

<!--centers the text, but does not work very fine -->
<!-- <style>body {text-align: justify}</style> -->

```{r importingMyLibraries, echo=F, results = "hide", message=F, warning=F}
#    ^ only output, not coding
#cmd+alt+i --> for r coding
#load libraries
library(diffobj)
library(gridExtra)
library(dplyr)
library(janitor)
library(ggplot2)
library(ineq)
library(chron)
library(maps)
library(tidyr)
library(plyr)
library(ggrepel)
library(knitr)
library(stringr)
library(reticulate)
library(pander)
library(kableExtra)
library(infer)
library(maps)

#function for reading csv and plotting it as table
knitTable <- function(path){
  df =  read.csv(file=path)
  kable(df, row.names = FALSE) %>%
    kable_styling(bootstrap_options = c("striped", "hover", "bordered"))
}

#declare python version to use (Comment Kim: I need this to knit the document.)
#use_python('/anaconda3/bin/python', required = TRUE)
```

#About the Data {#data}

The available data comes from an online shop, which sells beauty products. There are two datasets given: One with data about customer orders and another with data about customer clicks on the website.

The orders dataset consists of one row for each customer order in the time periode from the 28. January 2000 to the 3. March 2000. The data contains values such as the number of product units ordered, the total order amount, payment information, the manufacturer and brand names of the ordered products and social data about the customer, as by example his location or age.

The clicks dataset contains data referring to customer clicks on the website of the given company. Therefore, it is composed of data such as the timestamp of a click, the session length and the name of the clicked product, as well as the product category it belongs to. In this way the whole session course of a customer can be illustrated through the data.

Both datasets share a considerable amount of columns. However, since not every click results in an order and since a session consists normally of more than one click, the contents differ significantly.

<!-- ---------------------------------------------------------------------------------------------------------------------------------- -->
<!-- ---------------------------------------------------------------------------------------------------------------------------------- -->

#Task Description {#task}

The project's task is to analyze the dataset, especially by creating plots and statistical tables for the data, that is suspected to be relevant for the online shop in some way. 

In addition to that the performance of different Recomendation systems has to be analyzed.

<!-- TODO: Task description of the modelling task -->
Finally, a model has to be constructed to predict...

<!-- ---------------------------------------------------------------------------------------------------------------------------------- -->
<!-- ---------------------------------------------------------------------------------------------------------------------------------- -->

#Cleaning the Data {#cleaning}

Before we started cleaning the data, we copied it to the folder "0 Data". The reason for this was to avoid accidentally altering the original dataset by separating the edited datasets from the original ones. The cleaned data and further forms of the datasets were also saved to this folder. Before explaining the cleaning process, it makes sense to get an overview of the content of the aforementioned folder. It can be described as follows:

* Each file has a suffix depending on what language was used for creating it. Files created with a Python script have the suffix "_P", while files created with R have the suffix "_R". 
* For both datasets three types of files are created: 
    + A copy of the original dataset (e.g. "order_data_R.csv")
    + A cleaned version of that dataset (e.g. "order_data_cleaned_R.csv")
    + A smaller version of the cleaned data, which allows quick viewing and testing of the technical functionality of the coding (e.g. "order_data_small_R.csv")

<!-- TODO: Task description of the modelling task -->

<!-- ---------------------------------------------------------------------------------------------------------------------------------- -->
<!-- ---------------------------------------------------------------------------------------------------------------------------------- -->

##Cleaning with R
    
The cleaning process consists of the following steps:

1. Copy the original datasets to the folder "0 Data"

```{r copyFiles, eval=F, echo=F, results = "hide"}
# Path of original file
pathOrders <- "orders/order_data.csv"
# Path of original file to be pasted into the Data folder
newPathOrders <- "0 Data/order_data_R.csv"
# Path of the cleaned file
pathOrdersClean <- "0 Data/order_data_cleaned_R.csv"
# Path of the small version of the clean file
pathOrdersSmall = "0 Data/order_data_small_R.csv"
# Path of the headers
pathOrderHeaders <- "orders/order_columns.txt"

pathClicks <- "clickstream/clickstream_data.csv"
pathClicks2 <- "clickstream/clickstream_data_part_2.csv"
newPathClicks <- "0 Data/clickstream_data_R.csv"
newPathClicks2 <-"0 Data/clickstream_data_part_2_R.csv"
pathClicksClean  <- "0 Data/clickstream_data_cleaned_R.csv"
pathClicksSmall = "0 Data/clickstream_data_small_R.csv"
pathClicksHeaders <- "clickstream/clickstream_columns.txt"

# 1) Copy csv to data folder
file.copy(pathClicks, newPathClicks, overwrite = TRUE )
file.copy(pathClicks2, newPathClicks2, overwrite = TRUE )
file.copy(pathOrders, newPathOrders, overwrite = TRUE )
pathOrders <- newPathOrders
pathClicks <- newPathClicks
pathClicks2 <- newPathClicks2
```

2. Read the data, add headers (i.e. column labels), replace "?" and "NULL" with NA, drop columns which have a 100% ratio of missing data, reformat datetime cells and save the result (e.g. as "order_data_cleaned_R.csv")

```{r cleanFiles, eval=F, echo=F, results = "hide"}
# 2) read files, set headers and replace ? with NA

# Function to get headers from header.txt
getHeaders = function(filepath) {
    headers <- list()
    i <-1
    con <- file(filepath, "r")
    while ( TRUE ) {
        line <- readLines(con, n = 1)
        header <- gsub(":.*$","",line)
        if ( length(line) == 0 ) {
            break
        }
        headers[[i]] <- header
        i <- i+1
    }
    close(con)
    return(headers)
}

# get headers in an array
orderHeaders <- getHeaders(pathOrderHeaders)
clickHeaders <- getHeaders(pathClicksHeaders)

# read files, set headers, replace ? with NA and reformat time and date
orders <- read.csv(file=pathOrders, header=FALSE)

orders[orders=="?"]<-NA
orders[orders=="NULL"]<-NA
colnames(orders) <- orderHeaders
# drop columns which have only NA values
orders <- orders[,colSums(is.na(orders))<nrow(orders)]
# reformate date and time
for (col in names(orders)){
  if (grepl("Time",col)==TRUE){
    orders[,col]=gsub("\\\\", "", orders[,col])
  }
}
# save as new csv
write.table(orders, file = pathOrdersClean, sep=",", row.names=FALSE)

clicks <- read.csv(file=pathClicks, header=FALSE)
clicks2 <- read.csv(file=pathClicks2, header=FALSE)
clicks <- rbind(clicks,clicks2) 
clicks[clicks=="?"]<-NA
clicks[clicks=="NULL"]<-NA
colnames(clicks) <- clickHeaders
clicks <- clicks[,colSums(is.na(clicks))<nrow(clicks)]
for (col in names(clicks)){
  if (grepl("Time",col)==TRUE){
    clicks[,col]=gsub("\\\\", "", clicks[,col])
  }
}
write.table(clicks, file = pathClicksClean, sep=",", row.names=FALSE)
```

3. Create a subset of the cleaned data, containing only 1000 rows, and save it (e.g. as "order_data_small_R.csv")

```{r smallFiles, eval=F, echo=F, results = "hide"}
# 3) Save smaller versions for readability and dev purposes
small_size = min(1000,nrow(orders))
orders_small = orders[1:small_size,]
write.table(orders_small, file = pathOrdersSmall, sep=",", row.names=FALSE)

small_size = min(1000,nrow(clicks))
clicks_small = clicks[1:small_size,]
write.table(clicks_small, file = pathClicksSmall, sep=",", row.names=FALSE)
```
<!-- ---------------------------------------------------------------------------------------------------------------------------------- -->

##Cleaning with Python 

A similar cleaning process to the one explained above has been implemented in Python.

*Note: Python coding chunks are excutable in RMarkdown in general, but the Python environment is not persistent across different python chunks for the preview function ro run coding. Despite this, the chunks are compiled together, when the document is knitted.*

```{python pythonCleaning, eval=F, echo=F, results = "hide"}
import shutil
import pandas as pd
 
#paths
pathOrders = "orders/order_data.csv"
newPathOrders = "0 Data/order_data_P.csv"
pathOrdersClean = "0 Data/order_data_cleaned_P.csv"
pathOrdersSmall = "0 Data/order_data_small_P.csv"
pathOrdersHeaders = "orders/order_columns.txt"
 
pathClicks = "clickstream/clickstream_data.csv"
pathClicks2 = "clickstream/clickstream_data_part_2.csv"
newPathClicks = "0 Data/clickstream_data_P.csv"
pathClicksClean = "0 Data/clickstream_data_cleaned_P.csv"
pathClicksSmall = "0 Data/clickstream_data_small_P.csv"
pathClicksHeaders = "clickstream/clickstream_columns.txt"

#null values
nan = float('nan')

def headers(path):
    headers = open(path).\
              read().\
              split("\n")
    for counter, header in enumerate(headers):
        headers[counter] = (header.split(":"))[0]
        if not header: #for empty rows
            headers.pop(counter)
    return headers

def clean(df):
    #write NANs, delete empty columns
    df = df. \
         replace(to_replace="?", value=nan). \
         replace(to_replace="NULL", value=nan). \
         dropna(axis=1, how="all")
    #Clean Time and Date
    for column in df.columns:
        if "Time" in column:
            df[column] = df[column].\
                         str.\
                         replace('\\', '', regex=True)
    return df

# Copy files
shutil.copy(pathClicks, newPathClicks)
shutil.copy(pathOrders, newPathOrders)

pathOrders = newPathOrders
pathClicks = newPathClicks

# Read headers
clicksHeaders = headers(pathClicksHeaders)
ordersHeaders = headers(pathOrdersHeaders)

# Read data
clicks = pd.read_csv(pathClicks, sep=",", names=clicksHeaders, dtype=str, encoding="ISO-8859-1")
clicks2 = pd.read_csv(pathClicks2, sep=",", names=clicksHeaders, dtype=str, encoding="ISO-8859-1")
clicks = clean(clicks.append(clicks2))
orders = clean(pd.read_csv(pathOrders, sep=",", names=ordersHeaders, dtype=str, encoding="utf-8"))

# Save to CSV
clicks.to_csv(path_or_buf=pathClicksClean, index=False, encoding='utf-8')
(clicks.head(1000)).to_csv(path_or_buf=pathClicksSmall, index=False, encoding='utf-8')
orders.to_csv(path_or_buf=pathOrdersClean, index=False, encoding='utf-8')
(orders.head(1000)).to_csv(path_or_buf=pathOrdersSmall, index=False, encoding='utf-8')
```
<!-- ---------------------------------------------------------------------------------------------------------------------------------- -->

##Cleaning differences of Python and R {#diff}
To test if the cleaning scripts in Python and R result in the same file, execute the following code in RStudio. The package creates a diff view 

```{r diffFiles, eval=F}
library(diffobj)
pathOrders <- "0 Data/order_data_cleaned_R.csv"
pathClicks  <- "0 Data/clickstream_data_cleaned_R.csv"
pathOrdersPython <- "0 Data/order_data_cleaned_P.csv"
pathClicksPython  <- "0 Data/clickstream_data_cleaned_P.csv"

orders <- read.csv(file=pathOrders)
clicks <- read.csv(file=pathClicks)
clicksP = read.csv(file=pathClicksPython,na.strings=c("","NA"))
diffPrint(target=clicksP,current=clicks)
ordersP = read.csv(file=pathOrdersPython,na.strings=c("","NA"))
diffPrint(target=ordersP,current=orders)
```

<!-- ---------------------------------------------------------------------------------------------------------------------------------- -->

##Merging 
Furthermore, we tried to merge the click and order data in Python by trying different ID combinations that occure in both datasets. For testing the different combinations we used an inner join in order to be able to recognize easier whether a merging try had success. We tried the following combinations for merging the two datasets, which resulted in the shown shapes for the merged dataset:

```{python pythonMergingTries, echo=F}
import pandas as pd

pathIds = '1 Data Preprocessing/mergeIDs.csv'
pathOrders = '0 Data/order_data_cleaned_P.csv'
pathClicks = '0 Data/clickstream_data_cleaned_P.csv'

clicks = pd.read_csv(pathClicks, sep=",", dtype=str)
orders = pd.read_csv(pathOrders, sep=",", dtype=str)
ids = pd.read_csv(pathIds, sep=",", dtype=str)

shapes = []
for index, row in ids.iterrows():
    # Merging
    mergedData = pd.merge(clicks, orders, how='inner', left_on=[row['Clicks']], right_on=[row['Orders']])
    shapes.append(str(list(mergedData.shape)))
ids['Shape'] = shapes
```

```{r MergingTries, echo=F}
path <- '1 Data Preprocessing/mergeIDs.csv'
mergingTries <- read.csv(file=path)
kable(mergingTries, row.names = FALSE)
```

<br> 
This way we were able to discover that it is possible to join on the 'Customer ID' for some instances. Thus, we saved a dataset for the merging results on the Customer ID.

```{python pythonMerging, eval=F, echo=F, results = "hide"}
import pandas as pd

pathOrders = '../../0 Data/order_data_cleaned_P.csv'
pathClicks = '../../0 Data/clickstream_data_cleaned_P.csv'

pathMerge = "../../0 Data/merged_P.csv"
pathMergeSmall = "../../0 Data/merged_small_P.csv"

clicks = pd.read_csv(pathClicks, sep=",", dtype=str)
orders = pd.read_csv(pathOrders, sep=",", dtype=str)

# Merging
mergedData = pd.merge(clicks, orders, how='inner', left_on=['Customer ID'], right_on=['Customer ID'])

#Save CSV
mergedData.to_csv(path_or_buf=pathMerge, index=False)
(mergedData.head(10000)).to_csv(path_or_buf=pathMergeSmall, index=False)
```

<!-- ---------------------------------------------------------------------------------------------------------------------------------- -->
<!-- ---------------------------------------------------------------------------------------------------------------------------------- -->

#Analyzing the Data {#analysis}

The aim of the data analysis is to extract information, which is suspected to be valuable to the online shop, and prepare it in a way that makes it easily "digestible". The overview of the information is presented in statistical tables and plots.

<!-- ---------------------------------------------------------------------------------------------------------------------------------- -->

##Missing Data{#missingData}

Before creating overview tables or plots for columns, it makes sense to look which columns actually contain a large quantity of information and which do not. To do a check up on the ratio of filled cells, we created a ranking for both datasets containing column names and the percentage of missing data for each column. Columns with a low percentage of missing data are then preferred in later analysis steps. The first 50 entries in the resulting rankings can be seen in the following two tables.

```{r NARankingOrders, echo=F}
pathOrders <- "0 Data/order_data_cleaned_R.csv"
pathClicks  <- "0 Data/clickstream_data_cleaned_R.csv"
pathOrdersPython <- "0 Data/order_data_cleaned_P.csv"
pathClicksPython  <- "0 Data/clickstream_data_cleaned_P.csv"

pathNULLAnalysisOrders <- "2 Data Analysis/NAorders.csv"
pathNULLAnalysisClicks <- "2 Data Analysis/NAclicks.csv"

orders <- read.csv(file=pathOrders)
clicks <- read.csv(file=pathClicks)

# Create a DF to save the column names and appropriate NA percentage values
NAorders <- data.frame(matrix(ncol = 2, nrow = 0))
x <- c("Column_Name", "NA_percentage")
colnames(NAorders) <- x

# Get the NA percentage errors
for (column in names(orders)){
    percentageNA <- round(sum(is.na(orders[,column]))/length(orders[,column]),digits=4)
    NAorders[nrow(NAorders) + 1,] = list(column,percentageNA)
}
# Sort by NA percentage ascending
NAorders <- NAorders[with(NAorders, order(NAorders$NA_percentage)),]
kable(head(NAorders,50), row.names = FALSE)
```

```{r NARankingClicks, echo=F}
# Create a DF to save the column names and appropriate NA percentage values
NAclicks <- data.frame(matrix(ncol = 2, nrow = 0))
x <- c("Column_Name", "NA_percentage")
colnames(NAclicks) <- x

# Get the NA percentage errors
for (column in names(clicks)){
    percentageNA <- round(sum(is.na(clicks[,column]))/length(clicks[,column]),digits=4)
    NAclicks[nrow(NAclicks) + 1,] = list(column,percentageNA)
}
# Sort by NA percentage ascending
NAclicks <- NAclicks[with(NAclicks, order(NAclicks$NA_percentage)),]
write.table(NAclicks, file = pathNULLAnalysisClicks, sep=",", row.names=FALSE)
kable(head(NAclicks,50), row.names = FALSE)
```

<!-- ---------------------------------------------------------------------------------------------------------------------------------- -->

##Structure and Content 

###Order Data 

The order data can be mainly devided into 4 sections:

1) **Customer Data**: For this section we regard all information referring to the customer as an individual. This data contains information such as the customer gender, location, family status and retail activities.
```{r ordersCustomers, echo=FALSE, results = 'asis'}
interestingCustomers <- c("City",
                        "Country",
                        "US.State",
                        "Age",
                        "Marital.Status",
                        "Gender",
                        "Audience",
                        "Truck.Owner",
                        "RV.Owner",
                        "Motorcycle.Owner",
                        "Working.Woman",
                        "Presence.Of.Children",
                        "Speciality.Store.Retail",
                        "Oil.Retail.Activity",
                        "Bank.Retail.Activity",
                        "Finance.Retail.Activity",
                        "Miscellaneous.Retail.Activity",
                        "Upscale.Retail",
                        "Upscale.Speciality.Retail",
                        "Retail.Activity"
                        )
cat("\n")
for (title in interestingCustomers) {
  cat(paste("\t *", title, "\n")) 
}
```

2) **Product Data**: The following data columns describe features of the ordered products.
```{r ordersProducts, echo=FALSE, results = 'asis'}
interestingProducts <- c("StockType",
                        "Manufacturer",
                        "BrandName"
                        )
cat("\n")
for (title in interestingProducts) {
  cat(paste("\t *", title, "\n")) 
}
```

3) **Payment Data**: This sections contains columns which describe the payment methods used by the customers.
```{r ordersPayment, echo=FALSE, results = 'asis'}
interestingPayments <- c("Order.Credit.Card.Brand",
                        "Bank.Card.Holder",
                        "Gas.Card.Holder",
                        "Upscale.Card.Holder",
                        "Unknown.Card.Type",
                        "TE.Card.Holder",
                        "Premium.Card.Holder",
                        "New.Bank.Card"
                        )
cat("\n")
for (title in interestingPayments) {
  cat(paste("\t *", title, "\n")) 
}
```

4) **Order Data**: The order data section contains information describing the order process itself, such as order quantity and price data.
```{r ordersOrders, echo=FALSE, results = 'asis'}
interestingOrders <- c("Order.Line.Quantity",
                        "Order.Line.Unit.List.Price",
                        "Order.Line.Amount",
                        "Spend.Over..12.Per.Order.On.Average",
                        "Order.Line.Day.of.Week",
                        "Order.Line.Hour.of.Day",
                        "Order.Promotion.Code",
                        "Order.Discount.Amount"
                       )
cat("\n")
for (title in interestingOrders) {
  cat(paste("\t *", title, "\n")) 
}
```

###Clickstream Data 

The clickstream data has three main categories:

1) **Customer Data**: The data contains a vast collection of information about customers, reaching from usual informations like age, gender, etc. 
over payment information and finacnial activities to opinions about the shop.
```{r clicksCustomers, echo=FALSE, results = 'asis'}
clicksCustomerInfo <- c("WhichDoYouWearMostFrequent",
                        "YourFavoriteLegcareBrand",
                        "Registration.Gender",
                        "NumberOfChildren",
                        "DoYouPurchaseForOthers",
                        "HowDoYouDressForWork",
                        "HowManyPairsDoYouPurchase",
                        "YourFavoriteLegwearBrand",
                        "WhoMakesPurchasesForYou",
                        "NumberOfAdults",
                        "HowDidYouHearAboutUs",
                        "SendEmail",
                        "HowOftenDoYouPurchase",
                        "HowDidYouFindUs",
                        "City",
                        "US.State",
                        "Year.of.Birth",
                        "Email",
                        "Truck.Owner",
                        "RV.Owner",
                        "Motorcycle.Owner",
                        "Value.Of.All.Vehicles",
                        "Age",
                        "Other.Indiv...Age",
                        "Marital.Status",
                        "Working.Woman",
                        "Mail.Responder",
                        "Bank.Card.Holder",
                        "Gas.Card.Holder",
                        "Upscale.Card.Holder",
                        "Unknown.Card.Type",
                        "TE.Card.Holder",
                        "Premium.Card.Holder",
                        "Presence.Of.Children",
                        "Number.Of.Adults",
                        "Estimated.Income.Code",
                        "Home.Market.Value",
                        "New.Car.Buyer",
                        "Vehicle.Lifestyle",
                        "Property.Type",
                        "Loan.To.Value.Percent",
                        "Presence.Of.Pool",
                        "Year.House.Was.Built",
                        "Own.Or.Rent.Home",
                        "Length.Of.Residence",
                        "Mail.Order.Buyer",
                        "Year.Home.Was.Bought",
                        "Home.Purchase.Date",
                        "Number.Of.Vehicles",
                        "DMA.No.Mail.Solicitation.Flag",
                        "DMA.No.Phone.Solicitation.Flag",
                        "CRA.Income.Classification",
                        "New.Bank.Card",
                        "Number.Of.Credit.Lines",
                        "Speciality.Store.Retail",
                        "Oil.Retail.Activity",
                        "Bank.Retail.Activity",
                        "Finance.Retail.Activity",
                        "Miscellaneous.Retail.Activity",
                        "Upscale.Retail",
                        "Upscale.Speciality.Retail",
                        "Retail.Activity",
                        "Dwelling.Size",
                        "Dataquick.Market.Code",
                        "Lendable.Home.Equity",
                        "Home.Size.Range",
                        "Lot.Size.Range",
                        "Insurance.Expiry.Month",
                        "Dwelling.Unit.Size",
                        "Month.Home.Was.Bought",
                        "Available.Home.Equity",
                        "Minority.Census.Tract",
                        "Year.Of.Structure",
                        "Gender",
                        "Occupation",
                        "Other.Indiv...Gender",
                        "Other.Indiv...Occupation"
)
cat("\n")
for (title in clicksCustomerInfo) {
  cat(paste("\t *", title, "\n")) 
}
```

2) **Product Data**: The following data columns describe features of products clicked on by the customers.
```{r clicksProducts, echo=FALSE, results = 'asis'}
clicksProducts <- c("BrandName",
                    "UnitsPerInnerBox",
                    "PrimaryPackage",
                    "Depth",
                    "VendorMinREOrderDollars",
                    "Height",
                    "UnitsPerOuterBox",
                    "StockType",
                    "Pack",
                    "ProductForm",
                    "Look",
                    "BasicOrFashion",
                    "MfgStyleCode",
                    "SaleOrNonSale",
                    "Length",
                    "MinQty",
                    "LeadTime",
                    "Weight",
                    "HasDressingRoom",
                    "ColorOrScent",
                    "Width",
                    "Texture",
                    "Manufacturer",
                    "ToeFeature",
                    "Category2",
                    "Material",
                    "CategoryCode",
                    "UnitIncrement",
                    "WaistControl",
                    "Collection",
                    "BodyFeature",
                    "Audience",
                    "Category1",
                    "Product",
                    "Pattern"
)
cat("\n")
for (title in clicksProducts) {
  cat(paste("\t *", title, "\n")) 
}
```

3) **Time Data**: The following data columns describe different dates and times for clicks.
```{r clicksTimeinfo, echo=FALSE, results = 'asis'}
clicksTimeInfo <- c("Request.Date",
                    "Request.Date_Time",
                    "Request.Sequence",
                    "REQUEST_DAY_OF_WEEK",
                    "REQUEST_HOUR_OF_DAY",
                    "Cookie.First.Visit.Date",
                    "Cookie.First.Visit.Date_Time",
                    "Session.First.Request.Date",
                    "Session.First.Request.Date_Time",
                    "Session.Start.Login.Count",
                    "Session.Cookie.ID",
                    "Session.ID",
                    "Session.Customer.ID",
                    "Session.Visit.Count",
                    "Session.First.Content.ID",
                    "Session.First.Request.Day.of.Week",
                    "Session.First.Request.Hour.of.Day"
)
cat("\n")
for (title in clicksTimeInfo) {
  cat(paste("\t *", title, "\n")) 
}
```


<!-- ---------------------------------------------------------------------------------------------------------------------------------- -->

##Statistical Tables 

Given a subset of interesting columns, we create two types of statistical tables for each: One table for numerical columns in the subset and another for factors. The statistical table for the numerical data contains the maximum value, minimum value, mean, median and standard deviation for each column. Whereas the factorial tables contain the five most frequent factors as well as their percentage, the ratio of NAs and other factors for each column. For this, the NA percentage gets calculated at first, then the NA values are deleted from the regarded column and the percentage for each value is calcuated.

<!-- Describe stat table coding here -->

```{r createSummaryCSVFiles, echo=F, results = "hide", message=F, warning=F}
#count different values in column of dataframe (calculate ratio)
giveTop <- function(df, column, first, percentage){
  top <- (tabyl(df[[column]])) #create frequency table
  top[,c(1)] <- as.character(top[,c(1)])
  top[is.na(top)] <- "Not Available"
  naRow <- top %>%
    filter(top[[1]] == "Not Available")
  naRow <- naRow[,1:3]
  
  totalCount <- sum(top$n) # used when only the top x columns are requested
  if (percentage == TRUE){
    df <- subset(df, select=c(column))
    df <- na.omit(df)
    
    top <- (tabyl(df[[column]])) #create frequency table
    top[,c(1)] <- as.character(top[,c(1)])
    if (nrow(naRow)>0){
      top[nrow(top) + 1,] = naRow
    }
    
    top <- top %>% select(1, 3)
    names(top) <- c(column, "percentage") #rename
    top$percentage <- round(top$percentage*100, digits = 2)
    top <- arrange(top, desc(percentage))
  }
  else{
    top <- top %>% select(1:2)
    names(top) <- c(column, "amount") #rename
    top <- arrange(top, desc(amount))
  }
  #get the highest rating x columns only
  if (first != 0){
    if("Not Available" %in% top[,1]){
      first <- first+1
    }
    top <- head(top, first)
    if(percentage == TRUE){
      others <- max((100 - sum(top$percentage)),0) #Possible bug without max: others < 0 due to rounding
      top[nrow(top) + 1,] = list("Others",others)
      top <- arrange(top, desc(percentage))
    }
    else{
      others <- (totalCount-sum(top$amount))
      top[nrow(top) + 1,] = list("Others",others)
      top <- arrange(top, desc(amount))
    }
    
  }
  top[[column]] <- factor(top[[column]], levels=top[[column]]) #lockOrder
  return(top)
}

#summary function for numerical columns of tables
summarizeNumericalColumns <- function(df){
  df <- select_if(df, is.numeric)
    
  summary_stats <- data.frame(matrix(ncol = 6, nrow = 0))
  x <- c("Variable","Max", "Mean", "Median", "Min", "SD")
  colnames(summary_stats) <- x
    
  for (column in names(df)){
      maxValue <- max(df[[column]], na.rm = TRUE)
      meanValue <- round(mean(df[[column]], na.rm = TRUE),digits=2)
      medianValue <- median(df[[column]], na.rm = TRUE)
      minValue <- min(df[[column]], na.rm = TRUE)
      sdValue <- round(sd(df[[column]], na.rm = TRUE),digits=2)
      summary_stats[nrow(summary_stats) + 1,] = list(column,maxValue,meanValue,medianValue,minValue,sdValue)
    }
  
  return(summary_stats)
}

#summary function for factor columns of tables
summarizeFactorColumns <- function(df){
  df <- select_if(df, is.factor)
  
  summary_stats <- data.frame(matrix(ncol = 8, nrow = 0))
  x <- c("Variable","Top 1st","Top 2nd", "Top 3rd", "Top 4th", "Top 5th", "Others","Not Available")
  colnames(summary_stats) <- x
  
  for (column in names(df)){
    top <- giveTop(df,column,5,TRUE)
    Others <- paste("Others: ",round(top[top[,1]=="Others",][1,2], digits = 2),"%",sep="") # Use round to fix a bug where digits are added
    NotAvailable <- "Not Available: 0%"
    if ("Not Available" %in% top[,1]){
      NotAvailable <- paste("Not Available: ",top[top[,1]=="Not Available",][1,2],"%",sep="")
    }
    #Subset witohut entry for Others or NA
    pureTop <- top[top[,1]!="Others" & top[,1]!="Not Available",]
    summary <- c(column,"","","","","",Others,NotAvailable)
    loopStop <- min(10,nrow(pureTop))
    for (i in 1:loopStop){
      summary[i+1] <- paste(pureTop[i,1],": ",pureTop[i,2],"%",sep="")
    }
    summary_stats[nrow(summary_stats) + 1,] <- summary
  }
  summary_stats[['Others']] <- gsub('Others: ', '', summary_stats[['Others']])
  summary_stats[['Not Available']] <- gsub('Not Available: ', '', summary_stats[['Not Available']])
  return(summary_stats)
}

# create tables as csv to keep the following code chunks small

#-----------------------------------------------------------------------------------
#-----------------------------------------------------------------------------------
# Order data tables
#-----------------------------------------------------------------------------------
# order data
pathTableFolder <- "./4 Data Overview/Tables/"
interestingOrders <- c("Order.Line.Quantity",
                        "Order.Line.Unit.List.Price",
                        "Order.Line.Amount",
                        "Spend.Over..12.Per.Order.On.Average",
                        "Order.Line.Day.of.Week",
                        "Order.Line.Hour.of.Day",
                        "Order.Promotion.Code",
                        "Order.Discount.Amount"
)
subset <- subset(orders, select=interestingOrders)
facCol <- summarizeFactorColumns(subset)
numCol <- summarizeNumericalColumns(subset)
write.table(facCol, file = paste(pathTableFolder,"OrderData_Factors.csv"), sep=",", row.names=FALSE)
write.table(numCol, file = paste(pathTableFolder,"OrderData_Numerical.csv"), sep=",", row.names=FALSE)
#-----------------------------------------------------------------------------------
# payment method
interestingPayments <- c("Order.Credit.Card.Brand",
                        "Bank.Card.Holder",
                        "Gas.Card.Holder",
                        "Upscale.Card.Holder",
                        "Unknown.Card.Type",
                        "TE.Card.Holder",
                        "Premium.Card.Holder",
                        "New.Bank.Card"
)
subset <- subset(orders, select=interestingPayments)
facCol <- summarizeFactorColumns(subset)
write.table(facCol, file = paste(pathTableFolder,"PaymentMethodData_Factors.csv"), sep=",", row.names=FALSE)
#-----------------------------------------------------------------------------------
# product data
interestingProducts <- c("StockType",
                        "Manufacturer",
                        "BrandName"
)
subset <- subset(orders, select=interestingProducts)
facCol <- summarizeFactorColumns(subset)
write.table(facCol, file = paste(pathTableFolder,"ProductData_Factors.csv"), sep=",", row.names=FALSE)
#-----------------------------------------------------------------------------------
# customer data
interestingCustomers <- c("City",
                        "Country",
                        "US.State",
                        "Age",
                        "Marital.Status",
                        "Gender",
                        "Audience",
                        "Truck.Owner",
                        "RV.Owner",
                        "Motorcycle.Owner",
                        "Working.Woman",
                        "Presence.Of.Children",
                        "Speciality.Store.Retail",
                        "Oil.Retail.Activity",
                        "Bank.Retail.Activity",
                        "Finance.Retail.Activity",
                        "Miscellaneous.Retail.Activity",
                        "Upscale.Retail",
                        "Upscale.Speciality.Retail",
                        "Retail.Activity"
)
subset <- subset(orders, select=interestingCustomers)
facCol <- summarizeFactorColumns(subset)
numCol <- summarizeNumericalColumns(subset)
write.table(facCol, file = paste(pathTableFolder,"CustomerData_Factors.csv"), sep=",", row.names=FALSE)
write.table(numCol, file = paste(pathTableFolder,"CustomerData_Numerical.csv"), sep=",", row.names=FALSE)

#-----------------------------------------------------------------------------------
#-----------------------------------------------------------------------------------
# Overview table of interestng columns
#-----------------------------------------------------------------------------------
pathTableFolder <- "./4 Data Overview/Tables/"
clicksCustomerInfo <- c("WhichDoYouWearMostFrequent",
                        "YourFavoriteLegcareBrand",
                        "Registration.Gender",
                        "NumberOfChildren",
                        "DoYouPurchaseForOthers",
                        "HowDoYouDressForWork",
                        "HowManyPairsDoYouPurchase",
                        "YourFavoriteLegwearBrand",
                        "WhoMakesPurchasesForYou",
                        "NumberOfAdults",
                        "HowDidYouHearAboutUs",
                        "SendEmail",
                        "HowOftenDoYouPurchase",
                        "HowDidYouFindUs",
                        "City",
                        "US.State",
                        "Year.of.Birth",
                        "Email",
                        "Truck.Owner",
                        "RV.Owner",
                        "Motorcycle.Owner",
                        "Value.Of.All.Vehicles",
                        "Age",
                        "Other.Indiv...Age",
                        "Marital.Status",
                        "Working.Woman",
                        "Mail.Responder",
                        "Bank.Card.Holder",
                        "Gas.Card.Holder",
                        "Upscale.Card.Holder",
                        "Unknown.Card.Type",
                        "TE.Card.Holder",
                        "Premium.Card.Holder",
                        "Presence.Of.Children",
                        "Number.Of.Adults",
                        "Estimated.Income.Code",
                        "Home.Market.Value",
                        "New.Car.Buyer",
                        "Vehicle.Lifestyle",
                        "Property.Type",
                        "Loan.To.Value.Percent",
                        "Presence.Of.Pool",
                        "Year.House.Was.Built",
                        "Own.Or.Rent.Home",
                        "Length.Of.Residence",
                        "Mail.Order.Buyer",
                        "Year.Home.Was.Bought",
                        "Home.Purchase.Date",
                        "Number.Of.Vehicles",
                        "DMA.No.Mail.Solicitation.Flag",
                        "DMA.No.Phone.Solicitation.Flag",
                        "CRA.Income.Classification",
                        "New.Bank.Card",
                        "Number.Of.Credit.Lines",
                        "Speciality.Store.Retail",
                        "Oil.Retail.Activity",
                        "Bank.Retail.Activity",
                        "Finance.Retail.Activity",
                        "Miscellaneous.Retail.Activity",
                        "Upscale.Retail",
                        "Upscale.Speciality.Retail",
                        "Retail.Activity",
                        "Dwelling.Size",
                        "Dataquick.Market.Code",
                        "Lendable.Home.Equity",
                        "Home.Size.Range",
                        "Lot.Size.Range",
                        "Insurance.Expiry.Month",
                        "Dwelling.Unit.Size",
                        "Month.Home.Was.Bought",
                        "Available.Home.Equity",
                        "Minority.Census.Tract",
                        "Year.Of.Structure",
                        "Gender",
                        "Occupation",
                        "Other.Indiv...Gender",
                        "Other.Indiv...Occupation"
)

clicksProducts <- c("BrandName",
                    "UnitsPerInnerBox",
                    "PrimaryPackage",
                    "Depth",
                    "VendorMinREOrderDollars",
                    "Height",
                    "UnitsPerOuterBox",
                    "StockType",
                    "Pack",
                    "ProductForm",
                    "Look",
                    "BasicOrFashion",
                    "MfgStyleCode",
                    "SaleOrNonSale",
                    "Length",
                    "MinQty",
                    "LeadTime",
                    "Weight",
                    "HasDressingRoom",
                    "ColorOrScent",
                    "Width",
                    "Texture",
                    "Manufacturer",
                    "ToeFeature",
                    "Category2",
                    "Material",
                    "CategoryCode",
                    "UnitIncrement",
                    "WaistControl",
                    "Collection",
                    "BodyFeature",
                    "Audience",
                    "Category1",
                    "Product",
                    "Pattern"
)

selectUniqueCustomer <- clicks[ which(clicks$Request.Sequence==1), ]
subset <- subset(clicks, select=clicksCustomerInfo)
facCol <- summarizeFactorColumns(subset)
numCol <- summarizeNumericalColumns(subset)
write.table(facCol, file = paste(pathTableFolder,"ClickstreamDataCustomer_Factors.csv"), sep=",", row.names=FALSE)
write.table(numCol, file = paste(pathTableFolder,"ClickstreamDataCustomer_Numerical.csv"), sep=",", row.names=FALSE)

subset <- subset(clicks, select=clicksProducts)
facCol <- summarizeFactorColumns(subset)
numCol <- summarizeNumericalColumns(subset)
write.table(facCol, file = paste(pathTableFolder,"ClickstreamDataProducts_Factors.csv"), sep=",", row.names=FALSE)
write.table(numCol, file = paste(pathTableFolder,"ClickstreamDataProducts_Numerical.csv"), sep=",", row.names=FALSE)

```

###Order Data 

In the following section the statistical tables generated for the purpose of describing the order data are shown. Additionally, the most important or interesting analysis results are emphasized and shortly explained.

*Note: To support a better visualization, more relevant columns are highligthed in black color.*

####Customer Data 

Only the age can be regarded as a numerical customer data column here. As most intersting in this summary might appear the mean and the median, which both imply an average customer segment consisting of people in their late 30s.

```{r OrderCustomerNum, echo=FALSE}
knitTable("4 Data Overview/Tables/ CustomerData_Numerical.csv") %>%
  row_spec(1, bold = T, color = "white", background = "#000000")
```

The following data summary shows some social data for the shop's customer segment. Since all of the available data for the country column contains the value 'United States', it is highly probable that the online shop exclusively delivers customer located in the US. This was the reason for us to choose a map of the United States in order to visualize the customers' locations later on in the plotting. Furthermore, the data clearly shows that the main customer audience targeted are women.   

```{r OrderCustomerFac, echo=FALSE}
knitTable("4 Data Overview/Tables/ CustomerData_Factors.csv") %>%
  row_spec(2, bold = T, color = "white", background = "#000000") %>%
  row_spec(5, bold = T, color = "white", background = "#000000") %>%
  row_spec(6, bold = T, color = "white", background = "#000000")
```

####Product Data 

The selected columns belonging to the product information section show only factorial values. The statistical overview for the product data reveals that most of the sold articles are replenishable. The strongest brand in the current orders is American Essential, which seems to manufacture its articles by itself. Important is to recognize that the presented data is biased in a way: Because the given dataset shows only ordered products, it can be assumed that the popularity of articles distorts all percentual information referring to the products. Thus, we can not make any assumptions referring to the original product palette the store offers.

```{r OrderProductFac, echo=FALSE}
knitTable("4 Data Overview/Tables/ ProductData_Factors.csv") %>%
  column_spec(2, bold = T, color = "white", background = "#000000")
```

####Payment Data 

When it comes to the data concerning the used payment methods, there are only factorial columns as well. The most used credit card is by far the VISA card. Furthermore almost a fifth of the customers uses a premium card. From this information it could be deduced how wealthy the customer segment is by comparing the ratio of premium cards to the one in the whole population.

```{r OrderPayFac, echo=FALSE}
knitTable("4 Data Overview/Tables/ PaymentMethodData_Factors.csv") %>%
  row_spec(1, bold = T, color = "white", background = "#000000") %>%
  row_spec(8, bold = T, color = "white", background = "#000000")
```

####Order Process Data 

The numerical data for the order process shows that a customer usally buys one product per order. Also the order line amount implies that the store offers rather inexpensive articles. Furthermore, the minimum value for both the order line quantity and the order line amount is negative, which hints to the assumption of eather the order data containing returns as well or having errors in it. Through the discount amount it is possible to state that the store offers a maximum of a 50% price reduction for the given time period. Also the buyed articles got by average a discount of about 9%. Again it can be assumed that this data is not representative for the shop's offer in general, because it is probable that articles with a higher discount are bought more often.

```{r OrderOrderNum, echo=FALSE}
knitTable("4 Data Overview/Tables/ OrderData_Numerical.csv") %>%
  row_spec(1, bold = T, color = "white", background = "#000000") %>%
  row_spec(3, bold = T, color = "white", background = "#000000") %>%
  row_spec(5, bold = T, color = "white", background = "#000000")
```

The factors for the order process demonstrate that the 'FRIEND' discount is used most often and in the majority of the orders. (At this point it would be relevant for the interpretation to know for whom and under which circumstances this discount is given.) Also the weekday summary could be relevant for sales purposes, by example for finding out the most successfull time for showing ads to possible customers.
```{r OrderOrderFac, echo=FALSE}
knitTable("4 Data Overview/Tables/ OrderData_Factors.csv")  %>%
  row_spec(3, bold = T, color = "white", background = "#000000")
```

<!-- ---------------------------------------------------------------------------------------------------------------------------------- -->

###Clickstream Data 

####Customer Data 

tbd

```{r ClicksCustomerFac, echo=FALSE}
knitTable("4 Data Overview/Tables/ ClickstreamDataCustomer_Factors.csv")
```

```{r ClicksCustomerNum, echo=FALSE}
knitTable("4 Data Overview/Tables/ ClickstreamDataCustomer_Numerical.csv")
```

####Product Data 

tbd

```{r ClicksProductsFac, echo=FALSE}
knitTable("4 Data Overview/Tables/ ClickstreamDataProducts_Factors.csv")
```

```{r ClicksProductsNum, echo=FALSE}
knitTable("4 Data Overview/Tables/ ClickstreamDataProducts_Numerical.csv")
```


<!-- ---------------------------------------------------------------------------------------------------------------------------------- -->

##Plotting 
Some information is too complex to be compressed into a single table without making it too confusing or it's simply easier to understand if presented as a plot. The plot types used are time series plots, stacked bar plots, distribution curves, lorenz curves and maps.

###Order Data 

####Customer Data 
The customer data of the order data can be viewed from two perspectives: One way is to use every single order row for the creation of the visualizations and therby create a weighted view on the data, in which customers that have bought more products are more respected. Another possibility is to display the customer information just for every unique customer in the order data and disregard the number of orders a customer made. The following plottings will show both of this perspectives.

Firstly, we genereted some density curves for the attribute age to visualize the distribution of the customership. Also, we differentiated between the genders for this. The curves all show a fast rise in customership for the ages 20 to 40, which decreases slowly after a peak at about 35 to 40. When comparing the weighted and the normal graph, a slightly shift of the curve can be observed. This indicates that in general older people tend to order more. This is especially relevant for an older male customership, which is shown by the peak at about 55 in the male curve of the weighted density plot. Additionally, a less wide peak can be observed for the male customers, which has its maximum shortly before the age of 40. Furthermore, it should be regarded, that the gender plot shows a prozentual curve for each gender, but the ratio of customers differs by gender. 

```{r OrderPlotAge,echo=FALSE}
knitr::include_graphics(rep('./4 Data Overview/Plots/Customer Data Plots/Age_weighted.png', 1))
knitr::include_graphics(rep('./4 Data Overview/Plots/Customer Data Plots/Age.png', 1))
```

In order to show the customer location, we generated a map of the United States, which shows the cities with the highest customer numbers. From this it can be observed that the west coast of the US orders in general the most. The difference between the weighted and the other customer graph shows that the customership from the large cities like New York or San Franscisco tends to have high order numbers since the large circles at this cities disappear, when we look at the non-weighted graph. 

```{r OrderPlotCities,echo=FALSE}
knitr::include_graphics(rep('./4 Data Overview/Plots/Customer Data Plots/Cities_weighted.png', 1))
knitr::include_graphics(rep('./4 Data Overview/Plots/Customer Data Plots/Cities.png', 1))
```

To visualize the importance of different areas, we created a heatmap for the different US States. Here we can see that California and New York are the most important customer states. This is probably highly influenced by the big cities in this states. Here, the distorting factor of population density must be taken into account. 

```{r OrderPlotStates,echo=FALSE}
knitr::include_graphics(rep('./4 Data Overview/Plots/Customer Data Plots/States_weighted.png', 1))
knitr::include_graphics(rep('./4 Data Overview/Plots/Customer Data Plots/States.png', 1))
```

####Product Data
For the product Data, it has to be regarded that we here visualize the orders and thereby the characteristics of more often bought products have a higher influence. Because of this, the following plots should be seen as popularity graphs of different product attributes.

The following stacked bar plot shows the stock types for the top brands and manufactures. Most of them have a replenishable assortment. The biggest brands and manufacturers seem to have mixed stock types, which contain partly seasonal products. 
```{r OrderPlotStockPer,echo=FALSE}
knitr::include_graphics(rep('./4 Data Overview/Plots/Product Data Plots/StockPer.png', 1))
```


The lorenz curve of the products shows that only a quarter of the whole product quantity is responsible for about 75% of the ordered products. This indicates that some products have a very high popularity.
```{r OrderPlotProducts,echo=FALSE}
knitr::include_graphics(rep('./4 Data Overview/Plots/Product Data Plots/LorenzProducts.png', 1))
```

The manufacturer lorenz curve shows a real high ratio on orders for the biggest manufacturer, which leads to the assumptions that the popularity of some manufacturers is even higher than the product popularity.
```{r OrderPlotManufacturers,echo=FALSE}
knitr::include_graphics(rep('./4 Data Overview/Plots/Product Data Plots/LorenzManufacturer.png', 1))
```

The brand lorenz curve looks a little more flat, indicating a higher relevance for the manufacturer than for the brand.
```{r OrderPlotBrands,echo=FALSE}
knitr::include_graphics(rep('./4 Data Overview/Plots/Product Data Plots/LorenzBrandName.png', 1))
```

####Payment Data 

The stacked bar plot for credit card brands shows the ratio of each brand on premium and on upscale cards. The card brand AMEX is here noticable with a relative high ratio of premium and upscale cards.
```{r OrderPlotCards,echo=FALSE}
knitr::include_graphics(rep('./4 Data Overview/Plots/Payment Method Data/CardBrand.png', 1))
```

####Order Process Data 
For the order process data some graphs referring to the order amount and price were created. It has to be respected again that the order data can deform the graphs, by example it is imaginable that the customers tend to buy the cheaper products and therefore the average product price seems lower.

The density curve for the discount amount shows 3 peaks: The first one has a medium height and is around a discount of 0%, the second one is around the 10% mark and is pretty large, whereas the last peak is at a discount of 50% and is rather low. This might indicate that customers buy rather targeted than randomly.
```{r OrderPlotDiscouts,echo=FALSE}
knitr::include_graphics(rep('./4 Data Overview/Plots/Order Data Plots/Order Discounts.png', 1))
```

A density curve reflecting the order time is shown by the next plot. As to be expected the order amount goes down through the night. During the day the ordering is relative stable with some small peaks at 10 a.m. and in the afternoon. The activity in the afternoon can be explained by the average working hours, which mostly allow people only to spend time on online shopping at the afternoon and evening.
```{r OrderPlotTime,echo=FALSE}
knitr::include_graphics(rep('./4 Data Overview/Plots/Order Data Plots/Order Time.png', 1))
```

Next, there is displayed a graph, which summarizes some information on order behaviour. From this visulalization we can learn that the online shop sells products of a low price segments, but usually receives orders contaning a rather high amount (peak at 3-15) of articles. The different history plots on the right indicate a high activity in the first half of February, which drops in the beginning of the second month half and than slowly rises again. The first half could possibly be explained through customers buying presents for the valentines day (14th February).
```{r OrderPlotPrice,echo=FALSE}
knitr::include_graphics(rep('./4 Data Overview/Plots/Order Data Plots/Order Price.png', 1))
```

###Clickstream Data 

<!-- ---------------------------------------------------------------------------------------------------------------------------------- -->
<!-- ---------------------------------------------------------------------------------------------------------------------------------- -->

#Evaluating Recomendation Systems 

In addition to analyzing the order and clickstream data, we have to analyze the performance of different recommendation models. The performance of three different recommendation systems was measured:

* A profit based recommendation system: This one recommends products that shall fit the taste of the subject, but also generate high revenue shares.
* A ranking based recommendation system: This one recommends best performing products according to their sales rank.
* A random recommendation system: This one was used as a baseline treatment.

The evaluation of the profit and ranking based recommendation systems is done using inference analysis, specifically using the computational paradigm instead of the mathematical one. One test for each of the two recommendation systems is carried out with the null hypothesis always being that the system does not cause different sales than a purely random recommendation system. During each test we randomize our sample data 1000 times, using either permutation or bootstrapping, and measure the p-value and confidence interval. The test statistic, we always use, is the difference in mean between the group using the profit or ranking based Recomendation system and the group using the random recommendation system. 
If the null hypothesis was true, then the test statistic value for our sample would not significantly differ from the distribution of the test statistic for our randomized data. Our default alpha for the confidence interval is 5%, but since we conduct a total of two tests, we have to apply the Bonferroni correction and adjust the alpha we specify for our confidence interval to 2.5%.

Before diving into the inference analysis itself, we have to reformat our data for the recommendation systems into a form that is suitable for inference analysis. We want to have a data frame in which one row equals one customer, who was exposed to a recommendation system. We use three columns:

* Sales: The sales in Euro per customer.
* Used_Profit_Oriented_recommendations: 1 if the customer was exposed to the profit oriented recommendation system, otherwise 0.
* Used_Top_recommendations: 1 if the customer was exposed to the ranking based recommendation system, otherwise 0.

If the value in column Used_Top_recommendations and Used_Profit_Oriented_recommendations is 0, it means that the random recommendation system was used.

In the following code block we reformat the data and print the first 10 rows of the reformatted table.

```{r InferenceReformat, echo=FALSE}
pathExperiment <- "experiment/experimental_results.csv"
experiment <- read.csv(file=pathExperiment)

# Reformat the results to allow inference analysis
experimentDf <- data.frame(matrix(ncol = 3, nrow = 0))
x <- c("Sales_in_EUR","Used_Profit_Oriented_recommendations","Used_Top_recommendations")
colnames(experimentDf) <- x

for (row in 1:nrow(experiment)){
  random <- experiment[row, "random_recommendations"]
  profit <- experiment[row, "profit_oriented"]
  top <- experiment[row, "ranking_based"]
  if (!is.na(random)){
    experimentDf[nrow(experimentDf) + 1,] = list(random,0,0)
  }
  if (!is.na(profit)){
    experimentDf[nrow(experimentDf) + 1,] = list(profit,1,0)
  }
  if (!is.na(top)){
    experimentDf[nrow(experimentDf) + 1,] = list(top,0,1)
  }
}

experimentDf[,"Used_Profit_Oriented_recommendations"] <- factor(experimentDf[,"Used_Profit_Oriented_recommendations"])
experimentDf[,"Used_Top_recommendations"] <- factor(experimentDf[,"Used_Top_recommendations"])
experiment <- experimentDf

kable(head(experiment,10), row.names = FALSE) %>%
    kable_styling(bootstrap_options = c("striped", "hover", "bordered"))
```

##The Profit Oriented Recommendation System 

Now, we do an inference analysis for the profit oriented recommendation system. Firstly, we look at the p-value and the corresponding plot:

```{r InferenceProfitP, echo=FALSE}
# Do inference analysis
# Part 1: Test if the profit oriented recommendation system causes a significant difference in sales

obs_stat <- experiment %>% 
  filter(Used_Top_recommendations == 0) %>%
  specify(Sales_in_EUR ~ Used_Profit_Oriented_recommendations) %>%
  calculate(stat = "diff in means", order=c("1","0"))

permuted_stat <- experiment %>% 
  filter(Used_Top_recommendations == 0) %>%
  specify(Sales_in_EUR ~ Used_Profit_Oriented_recommendations) %>%
  hypothesize(null = "independence") %>%
  generate(reps = 1000, type="permute") %>%
  calculate(stat = "diff in means", order=c("1","0"))

p_val <- permuted_stat %>%
  get_p_value(obs_stat = obs_stat, direction = "two_sided")
print(paste("p-value = ",as.data.frame(p_val)[1,1],sep=""))

viz_plot <- permuted_stat %>% visualize()
viz_plot <- viz_plot + shade_p_value(obs_stat, direction = "two_sided", color = "black", fill = "grey")
print(viz_plot)
```

The plot shows us the distribution of the test statistic for the 1000 randomized samples. The test statistic value for our sample is represented by a black line. The two-sided p-value regions are marked by a grey background. If our null hypothesis were true, then the test statistic value of our sample would be somewhere in the distribution of the test statistic for the randomized samples. Every test statistic value for a randomized sample, which lies in the p-value region, increases the p-value.

As we can see the test statistic value of our sample is pretty far away from the test statistic values of the randomized samples. This already shows, without looking at the p-value itself, that the profit oriented recommendation system causes a significant difference in the sales in Euro. The value of the p-value is 0, which reaffirms our interpretation of the plot.

Now, we look at the confidence interval:

```{r InferenceProfitCI, echo=FALSE}
bootstrap_stat <- experiment %>%
  filter(Used_Top_recommendations == 0) %>%
  specify(Sales_in_EUR ~ Used_Profit_Oriented_recommendations) %>%
  generate(reps = 1000, type = "bootstrap") %>%
  calculate(stat = "diff in means", order = c("1", "0"))

# Bonferroni correction: Default alpha = 5%, number of tests = 2 -> Set alpha to 2.5% -> level = 0.95
ci <- bootstrap_stat %>%
  get_confidence_interval(level = 0.95)
kable(ci, row.names = FALSE) %>%
    kable_styling(bootstrap_options = c("striped", "hover", "bordered"))
lowerBound <- round(as.data.frame(ci)[1,1],digits=2)
upperBound <- round(as.data.frame(ci)[1,2],digits=2)

viz_plot <- bootstrap_stat[complete.cases(bootstrap_stat), ] %>% visualize()
viz_plot <- viz_plot + shade_confidence_interval(ci, color = "black", fill = "grey")
print(viz_plot)
```

As we can see, there is a 95% chance that for the global population customers, who get profit oriented recommendations, spend on average `r lowerBound`â¬-`r upperBound`â¬ more than people who get random recommendations.

##The Ranking Based Recommendation System 

Now we do an inference analysis for the ranking based recommendation system. Firstly, we look at the p-value and the corresponding plot:

```{r InferenceRankingP, echo=FALSE}
# Part 2: Test if the popular products recommendation system causes a significant difference in sales

obs_stat <- experiment %>% 
  filter(Used_Profit_Oriented_recommendations == 0) %>%
  specify(Sales_in_EUR ~ Used_Top_recommendations) %>%
  calculate(stat = "diff in means", order=c("1","0"))

permuted_stat <- experiment %>% 
  filter(Used_Profit_Oriented_recommendations == 0) %>%
  specify(Sales_in_EUR ~ Used_Top_recommendations) %>%
  hypothesize(null = "independence") %>%
  generate(reps = 1000, type="permute") %>%
  calculate(stat = "diff in means", order=c("1","0"))

p_val <- permuted_stat %>%
  get_p_value(obs_stat = obs_stat, direction = "two_sided")
print(paste("p-value = ",as.data.frame(p_val)[1,1],sep=""))

viz_plot <- permuted_stat %>% visualize()
viz_plot <- viz_plot + shade_p_value(obs_stat, direction = "two_sided", color = "black", fill = "grey")
print(viz_plot)
```

In this plot quite some portions of the distribution of the test statistic for our random samples lie in the p-value zone. This is also shown by the p-value `r as.data.frame(p_val)[1,1]`, which greater than 0.025. This means that for our alpha = 0.05 the effect of the ranking based recommendation system is statistically insignificant.

Now we look at the confidence interval:

```{r InferenceRankingCI, echo=FALSE}
bootstrap_stat <- experiment %>%
  filter(Used_Profit_Oriented_recommendations == 0) %>%
  specify(Sales_in_EUR ~ Used_Top_recommendations) %>%
  generate(reps = 1000, type = "bootstrap") %>%
  calculate(stat = "diff in means", order = c("1", "0"))

# Bonferroni correction: Default alpha = 5%, number of tests = 2 -> Set alpha to 2.5% -> level = 0.95
ci <- bootstrap_stat %>%
  get_confidence_interval(level = 0.95)
kable(ci, row.names = FALSE) %>%
    kable_styling(bootstrap_options = c("striped", "hover", "bordered"))
lowerBound <- round(as.data.frame(ci)[1,1],digits=2)
upperBound <- round(as.data.frame(ci)[1,2],digits=2)

viz_plot <- bootstrap_stat[complete.cases(bootstrap_stat), ] %>% visualize()
viz_plot <- viz_plot + shade_confidence_interval(ci, color = "black", fill = "grey")
print(viz_plot)
```

Since the confidence interval includes the value 0, it shows us that the effect is statistically insignificant.

##Summary 

To sum it up, the company should use the profit oriented recommendation system, since out of the two tested systems it causes the largest increase in sales. The ranking based recommendation system does not cause any statistically relevant difference in sales. However if the effect was something else than sales in Euro per person, then the results could be different. The company should ask itself if the goal of their recommendation system should really be to increase sales. Maybe at some point in time it could introduce a subscription business model, similar to that of Amazon. In that case it might also want to increase the percentage of customers that have a subscription.

<!-- ---------------------------------------------------------------------------------------------------------------------------------- -->
<!-- ---------------------------------------------------------------------------------------------------------------------------------- -->

#Creating a Model {#model}

<!-- ---------------------------------------------------------------------------------------------------------------------------------- -->
<!-- ---------------------------------------------------------------------------------------------------------------------------------- -->

#Summary {#summary}

<!-- ---------------------------------------------------------------------------------------------------------------------------------- -->
<!-- ---------------------------------------------------------------------------------------------------------------------------------- -->